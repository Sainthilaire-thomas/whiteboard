# TaggingDataContext - Documentation

## Vue d'ensemble

Le `TaggingDataContext` est un contexte sp√©cialis√© pour la fonctionnalit√© de **tagging des appels** . Il g√®re les appels d√©di√©s au tagging, leurs transcriptions, les tags appliqu√©s et un lecteur audio int√©gr√© pour l'annotation temporelle des conversations.

**Localisation :** `context/TaggingDataContext.tsx`

## Fonctionnalit√©s principales

- **Appels de tagging** : Gestion des appels sp√©cialement marqu√©s pour le tagging
- **Transcriptions d√©di√©es** : Chargement et affichage des mots pour navigation
- **Syst√®me de tags** : Cr√©ation, application et suppression de tags temporels
- **Lecteur audio int√©gr√©** : Player avec navigation temporelle
- **Tags enrichis** : Association tags avec couleurs et m√©tadonn√©es
- **Post-its de tagging** : Annotations sp√©cifiques aux appels de tagging

## Interface TaggingDataContextType

```typescript
interface TaggingDataContextType {
  // üìû Appels de tagging
  taggingCalls: Call[]; // Appels d√©di√©s au tagging
  setTaggingCalls: React.Dispatch<React.SetStateAction<Call[]>>; // Setter direct
  selectedTaggingCall: Call | null; // Appel actuellement s√©lectionn√©
  selectTaggingCall: (call: Call) => void; // S√©lection avec chargement auto
  callId: string | undefined; // ID de l'appel s√©lectionn√©

  // üìö Transcriptions
  taggingTranscription: Word[]; // Mots de la transcription
  fetchTaggingTranscription: (callId: string) => Promise<void>; // Chargement transcription

  // üóíÔ∏è Post-its de tagging
  taggingPostits: Postit[]; // Post-its de l'appel s√©lectionn√©

  // üéµ Lecteur audio int√©gr√©
  audioSrc: string | null; // Source audio
  setAudioSrc: (src: string | null) => void; // Changement source
  playerRef: React.RefObject<HTMLAudioElement | null>; // R√©f√©rence player HTML
  playAudioAtTimestamp: (timestamp: number) => void; // Navigation + lecture
  updateCurrentWord: (word: Word) => void; // MAJ mot courant
  currentWord: Word | null; // Mot actuellement lu

  // üè∑Ô∏è Syst√®me de tags
  taggedTurns: TaggedTurn[]; // Tours de parole tagg√©s
  fetchTaggedTurns: (callId: string) => Promise<void>; // Chargement tags existants
  addTag: (newTag: Partial<TaggedTurn>) => Promise<TaggedTurn | null>; // Ajout tag
  deleteTurnTag: (id: string) => Promise<void>; // Suppression tag
  tags: Tag[]; // D√©finitions des tags disponibles
  setTags: (tags: Tag[]) => void; // MAJ tags disponibles
}
```

## Types de donn√©es sp√©cialis√©s

### Call (Appel de tagging)

```typescript
interface Call {
  callid: string; // ID unique de l'appel
  audiourl?: string; // URL audio directe
  [key: string]: any; // Autres propri√©t√©s flexibles
}
```

### Word (Mot de transcription)

```typescript
interface Word {
  id: string; // ID unique du mot
  transcriptid: string; // ID de la transcription parent
  startTime: number; // Temps de d√©but (secondes)
  endTime: number; // Temps de fin (secondes)
  word: string; // Texte du mot
}
```

### TaggedTurn (Tour de parole tagg√©)

```typescript
interface TaggedTurn {
  id: string; // ID unique du tag
  call_id: string; // ID de l'appel
  start_time: number; // D√©but du segment (secondes)
  end_time: number; // Fin du segment (secondes)
  tag: string; // Label du tag appliqu√©
  next_turn_verbatim?: string; // Verbatim du tour suivant
  color?: string; // Couleur associ√©e (enrichie)
}
```

### Tag (D√©finition de tag)

```typescript
interface Tag {
  id: string; // ID unique
  tag: string; // Label du tag
  color?: string; // Couleur hexadecimale
}
```

## Architecture interne

### √âtats principaux

```typescript
// üìû Appels et s√©lection
const [taggingCalls, setTaggingCalls] = useState<Call[]>([]);
const [selectedTaggingCall, setSelectedTaggingCall] = useState<Call | null>(
  null
);

// üìö Transcription et post-its
const [taggingTranscription, setTaggingTranscription] = useState<Word[]>([]);
const [taggingPostits, setTaggingPostits] = useState<Postit[]>([]);

// üéµ Lecteur audio
const [audioSrc, setAudioSrc] = useState<string | null>(null);
const playerRef = useRef<HTMLAudioElement | null>(null);
const [currentWord, setCurrentWord] = useState<Word | null>(null);

// üè∑Ô∏è Tags
const [taggedTurns, setTaggedTurns] = useState<TaggedTurn[]>([]);
const [tags, setTags] = useState<Tag[]>([]);
```

### Initialisation automatique

```typescript
// Chargement initial des d√©finitions de tags
useEffect(() => {
  const fetchTags = async () => {
    const { data, error } = await supabaseClient.from("lpltag").select("*");

    if (error) {
      console.error("Erreur de r√©cup√©ration des tags:", error.message);
    } else {
      setTags(data ?? []);
    }
  };
  fetchTags();
}, []);
```

## Fonctionnalit√©s d√©taill√©es

### üìû Gestion des appels de tagging

#### R√©cup√©ration des appels sp√©cialis√©s

```typescript
const fetchTaggingCalls = useCallback(async () => {
  const { data, error } = await supabaseClient
    .from("call")
    .select("*")
    .eq("is_tagging_call", true) // ‚úÖ Filtre appels de tagging
    .eq("preparedfortranscript", true); // ‚úÖ Avec transcription pr√™te

  if (error) {
    console.error("Erreur lors du fetch des appels:", error);
  } else {
    setTaggingCalls(data ?? []);
  }
}, []);
```

#### S√©lection avec chargement automatique

```typescript
const selectTaggingCall = useCallback(
  (call: Call) => {
    setSelectedTaggingCall(call);

    if (call.callid) {
      // Chargement automatique des donn√©es li√©es
      fetchTaggingTranscription(call.callid);
      fetchTaggingPostits(call.callid);
      fetchTaggedTurns(call.callid);

      // Configuration du lecteur audio
      setAudioSrc(call.audiourl ?? null);
    }
  },
  [fetchTaggingTranscription, fetchTaggingPostits, fetchTaggedTurns]
);
```

### üìö Gestion des transcriptions

#### Chargement en deux √©tapes

```typescript
const fetchTaggingTranscription = useCallback(async (callId: string) => {
  // √âtape 1 : R√©cup√©ration de l'ID transcription
  const { data: transcriptData, error: transcriptError } = await supabaseClient
    .from("transcript")
    .select("transcriptid")
    .eq("callid", callId)
    .single();

  if (transcriptError || !transcriptData?.transcriptid) {
    console.warn("Transcript ID introuvable pour l'appel:", callId);
    setTaggingTranscription([]);
    return;
  }

  // √âtape 2 : R√©cup√©ration des mots ordonn√©s
  const { data: wordsData, error: wordsError } = await supabaseClient
    .from("word")
    .select("*")
    .eq("transcriptid", transcriptData.transcriptid)
    .order("startTime", { ascending: true });

  if (wordsError) {
    console.error("Erreur de r√©cup√©ration des mots:", wordsError);
  } else {
    setTaggingTranscription(wordsData ?? []);
  }
}, []);
```

### üè∑Ô∏è Syst√®me de tags avanc√©

#### R√©cup√©ration avec enrichissement couleurs

```typescript
const fetchTaggedTurns = useCallback(
  async (callId: string) => {
    const { data: turnsData, error } = await supabaseClient
      .from("turntagged")
      .select(
        `
      id,
      call_id,
      start_time,
      end_time,
      tag,
      next_turn_verbatim
    `
      )
      .eq("call_id", callId);

    if (error) {
      console.error("Erreur de r√©cup√©ration des tags:", error);
      return;
    }

    // ‚úÖ Enrichissement avec couleurs des tags
    const enrichedTags = (turnsData ?? []).map((turn) => {
      const matchingTag = tags.find((t) => t.tag === turn.tag);
      return {
        ...turn,
        color: matchingTag?.color ?? "transparent",
      };
    });

    setTaggedTurns(enrichedTags);
  },
  [tags]
); // ‚úÖ D√©pendance sur tags pour re-enrichir
```

#### Ajout de tags avec enrichissement

```typescript
const addTag = useCallback(async (newTag: Partial<TaggedTurn>) => {
  const { data, error } = await supabaseClient
    .from("turntagged")
    .insert([newTag])
    .select(
      "id, call_id, start_time, end_time, tag, next_turn_verbatim, lpltag(color)"
    );

  if (error) {
    console.error("Erreur lors de l'ajout du tag:", error);
    return null;
  }

  if (data?.length) {
    // ‚úÖ Enrichissement imm√©diat avec couleur
    const enrichedTag = {
      ...data[0],
      color: data[0].lpltag[0]?.color || "transparent",
    };

    setTaggedTurns((prev) => [...prev, enrichedTag]);
    return enrichedTag;
  }

  return null;
}, []);
```

#### Suppression de tags

```typescript
const deleteTurnTag = useCallback(async (id: string) => {
  const { error } = await supabaseClient
    .from("turntagged")
    .delete()
    .eq("id", id);

  if (error) {
    console.error("Erreur lors de la suppression du tag:", error.message);
  } else {
    // ‚úÖ Mise √† jour locale imm√©diate
    setTaggedTurns((prev) => prev.filter((tag) => tag.id !== id));
  }
}, []);
```

### üéµ Lecteur audio int√©gr√©

#### Navigation temporelle

```typescript
const playAudioAtTimestamp = (timestamp: number) => {
  if (audioSrc && playerRef.current) {
    playerRef.current.currentTime = timestamp;
    playerRef.current.play();
  }
};
```

#### Mise √† jour du mot courant

```typescript
const updateCurrentWord = (word: Word) => setCurrentWord(word);

// Usage dans les composants
const handleWordClick = (word: Word) => {
  updateCurrentWord(word);
  playAudioAtTimestamp(word.startTime);
};
```

## Provider et utilisation

### TaggingDataProvider

```typescript
interface TaggingDataProviderProps {
  children: ReactNode;
}

export const TaggingDataProvider = ({ children }: TaggingDataProviderProps) => {
  // Tous les √©tats et fonctions d√©taill√©s ci-dessus

  return (
    <TaggingDataContext.Provider value={{
      // üìû Appels
      taggingCalls,
      setTaggingCalls,
      selectedTaggingCall,
      selectTaggingCall,
      callId: selectedTaggingCall?.callid,

      // üìö Transcription
      taggingTranscription,
      fetchTaggingTranscription,

      // üóíÔ∏è Post-its
      taggingPostits,

      // üéµ Audio
      audioSrc,
      setAudioSrc,
      playerRef,
      playAudioAtTimestamp,
      updateCurrentWord,
      currentWord,

      // üè∑Ô∏è Tags
      taggedTurns,
      fetchTaggedTurns,
      addTag,
      deleteTurnTag,
      tags,
      setTags,
    }}>
      {children}
    </TaggingDataContext.Provider>
  );
};
```

### Hook d'utilisation

```typescript
export const useTaggingData = (): TaggingDataContextType => {
  const context = useContext(TaggingDataContext);
  if (!context) {
    throw new Error("useTaggingData must be used within a TaggingDataProvider");
  }
  return context;
};
```

## Cas d'usage fr√©quents

### Interface de s√©lection d'appel

```typescript
function TaggingCallSelector() {
  const {
    taggingCalls,
    selectedTaggingCall,
    selectTaggingCall
  } = useTaggingData();

  return (
    <div className="call-selector">
      <h3>Appels de Tagging</h3>
      {taggingCalls.map(call => (
        <button
          key={call.callid}
          onClick={() => selectTaggingCall(call)}
          className={selectedTaggingCall?.callid === call.callid ? 'selected' : ''}
        >
          {call.filename || `Appel ${call.callid}`}
        </button>
      ))}
    </div>
  );
}
```

### Interface de tagging temporel

```typescript
function TemporalTaggingInterface() {
  const {
    taggingTranscription,
    taggedTurns,
    addTag,
    deleteTurnTag,
    tags,
    playAudioAtTimestamp,
    currentWord,
    selectedTaggingCall
  } = useTaggingData();

  const [selectionStart, setSelectionStart] = useState<number | null>(null);
  const [selectionEnd, setSelectionEnd] = useState<number | null>(null);
  const [selectedTag, setSelectedTag] = useState<string>('');

  const handleWordClick = (word: Word, index: number) => {
    if (!selectionStart) {
      setSelectionStart(index);
    } else if (!selectionEnd) {
      setSelectionEnd(index);
    } else {
      // Reset s√©lection
      setSelectionStart(index);
      setSelectionEnd(null);
    }

    playAudioAtTimestamp(word.startTime);
  };

  const applyTag = async () => {
    if (selectionStart !== null && selectionEnd !== null && selectedTag && selectedTaggingCall) {
      const startWord = taggingTranscription[selectionStart];
      const endWord = taggingTranscription[selectionEnd];

      const newTag = {
        call_id: selectedTaggingCall.callid,
        start_time: startWord.startTime,
        end_time: endWord.endTime,
        tag: selectedTag,
        next_turn_verbatim: taggingTranscription
          .slice(selectionStart, selectionEnd + 1)
          .map(w => w.word)
          .join(' ')
      };

      await addTag(newTag);

      // Reset s√©lection
      setSelectionStart(null);
      setSelectionEnd(null);
      setSelectedTag('');
    }
  };

  return (
    <div className="temporal-tagging">
      {/* Contr√¥les de tagging */}
      <div className="tagging-controls">
        <select
          value={selectedTag}
          onChange={e => setSelectedTag(e.target.value)}
        >
          <option value="">Choisir un tag</option>
          {tags.map(tag => (
            <option key={tag.id} value={tag.tag}>{tag.tag}</option>
          ))}
        </select>

        <button
          onClick={applyTag}
          disabled={!selectionStart || !selectionEnd || !selectedTag}
        >
          Appliquer Tag
        </button>
      </div>

      {/* Transcription avec s√©lection */}
      <div className="transcription">
        {taggingTranscription.map((word, index) => (
          <span
            key={word.id}
            onClick={() => handleWordClick(word, index)}
            className={`word ${
              currentWord?.id === word.id ? 'current' :
              index >= (selectionStart || -1) && index <= (selectionEnd || -1) ? 'selected' : ''
            }`}
            style={{
              cursor: 'pointer',
              margin: '0 2px',
              padding: '2px 4px',
              backgroundColor: currentWord?.id === word.id ? 'yellow' :
                              index >= (selectionStart || -1) && index <= (selectionEnd || -1) ? 'lightblue' : 'transparent'
            }}
          >
            {word.word}
          </span>
        ))}
      </div>

      {/* Tags existants */}
      <div className="existing-tags">
        <h4>Tags appliqu√©s:</h4>
        {taggedTurns.map(taggedTurn => (
          <div
            key={taggedTurn.id}
            className="tagged-turn"
            style={{
              borderLeft: `4px solid ${taggedTurn.color}`,
              padding: '8px',
              margin: '4px 0'
            }}
          >
            <div className="tag-info">
              <strong>{taggedTurn.tag}</strong>
              <span>({taggedTurn.start_time}s - {taggedTurn.end_time}s)</span>
              <button
                onClick={() => deleteTurnTag(taggedTurn.id)}
                className="delete-tag"
              >
                √ó
              </button>
            </div>
            {taggedTurn.next_turn_verbatim && (
              <div className="verbatim">
                "{taggedTurn.next_turn_verbatim}"
              </div>
            )}
          </div>
        ))}
      </div>
    </div>
  );
}
```

### Lecteur audio avec synchronisation

```typescript
function TaggingAudioPlayer() {
  const {
    audioSrc,
    playerRef,
    currentWord,
    taggingTranscription,
    playAudioAtTimestamp
  } = useTaggingData();

  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);

  useEffect(() => {
    const player = playerRef.current;
    if (!player) return;

    const handleTimeUpdate = () => {
      const time = player.currentTime;
      setCurrentTime(time);

      // Trouver le mot courant
      const currentWordIndex = taggingTranscription.findIndex(word =>
        time >= word.startTime && time < word.endTime
      );

      if (currentWordIndex >= 0) {
        updateCurrentWord(taggingTranscription[currentWordIndex]);
      }
    };

    const handlePlay = () => setIsPlaying(true);
    const handlePause = () => setIsPlaying(false);

    player.addEventListener('timeupdate', handleTimeUpdate);
    player.addEventListener('play', handlePlay);
    player.addEventListener('pause', handlePause);

    return () => {
      player.removeEventListener('timeupdate', handleTimeUpdate);
      player.removeEventListener('play', handlePlay);
      player.removeEventListener('pause', handlePause);
    };
  }, [taggingTranscription]);

  const togglePlayPause = () => {
    const player = playerRef.current;
    if (!player) return;

    if (isPlaying) {
      player.pause();
    } else {
      player.play();
    }
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="tagging-audio-player">
      {/* Contr√¥les */}
      <div className="controls">
        <button onClick={togglePlayPause}>
          {isPlaying ? '‚è∏Ô∏è' : '‚ñ∂Ô∏è'}
        </button>
        <span className="time">
          {formatTime(currentTime)}
        </span>
      </div>

      {/* Lecteur audio invisible */}
      <audio ref={playerRef} src={audioSrc || undefined} />

      {/* Timeline visuelle */}
      <div className="timeline">
        {taggedTurns.map(tag => {
          const position = (tag.start_time / (playerRef.current?.duration || 1)) * 100;
          const width = ((tag.end_time - tag.start_time) / (playerRef.current?.duration || 1)) * 100;

          return (
            <div
              key={tag.id}
              className="timeline-tag"
              style={{
                position: 'absolute',
                left: `${position}%`,
                width: `${width}%`,
                backgroundColor: tag.color,
                height: '8px',
                cursor: 'pointer',
                opacity: 0.7
              }}
              onClick={() => playAudioAtTimestamp(tag.start_time)}
              title={`${tag.tag}: ${tag.start_time}s - ${tag.end_time}s`}
            />
          );
        })}
      </div>
    </div>
  );
}
```

## Optimisations et performance

### Chargement conditionnel des donn√©es

```typescript
// Chargement seulement si appel s√©lectionn√©
const selectTaggingCall = useCallback((call: Call) => {
  setSelectedTaggingCall(call);

  if (call.callid) {
    // Parall√©lisation des chargements
    Promise.all([
      fetchTaggingTranscription(call.callid),
      fetchTaggingPostits(call.callid),
      fetchTaggedTurns(call.callid),
    ]);

    setAudioSrc(call.audiourl ?? null);
  }
}, []);
```

### Enrichissement en temps r√©el

```typescript
// Re-enrichissement automatique quand les tags changent
const fetchTaggedTurns = useCallback(
  async (callId: string) => {
    // ... r√©cup√©ration des donn√©es

    // Enrichissement avec couleurs actuelles
    const enrichedTags = turnsData.map((turn) => {
      const matchingTag = tags.find((t) => t.tag === turn.tag);
      return {
        ...turn,
        color: matchingTag?.color ?? "transparent",
      };
    });

    setTaggedTurns(enrichedTags);
  },
  [tags]
); // ‚úÖ Red√©clenche quand tags changent
```

### Gestion m√©moire optimis√©e

```typescript
// Nettoyage √† la d√©s√©lection
const deselectCall = () => {
  setSelectedTaggingCall(null);
  setTaggingTranscription([]);
  setTaggingPostits([]);
  setTaggedTurns([]);
  setAudioSrc(null);
  setCurrentWord(null);
};
```

## Int√©gration avec base de donn√©es

### Structure des tables

```sql
-- Table des appels de tagging
CREATE TABLE call (
  callid varchar PRIMARY KEY,
  audiourl text,
  is_tagging_call boolean DEFAULT false,
  preparedfortranscript boolean DEFAULT false
);

-- Table des d√©finitions de tags
CREATE TABLE lpltag (
  id varchar PRIMARY KEY,
  tag varchar UNIQUE,
  color varchar
);

-- Table des tours tagg√©s
CREATE TABLE turntagged (
  id varchar PRIMARY KEY,
  call_id varchar REFERENCES call(callid),
  start_time numeric,
  end_time numeric,
  tag varchar REFERENCES lpltag(tag),
  next_turn_verbatim text
);

-- Table des transcriptions
CREATE TABLE transcript (
  transcriptid varchar PRIMARY KEY,
  callid varchar REFERENCES call(callid)
);

-- Table des mots
CREATE TABLE word (
  id varchar PRIMARY KEY,
  transcriptid varchar REFERENCES transcript(transcriptid),
  startTime numeric,
  endTime numeric,
  word varchar
);
```

### Requ√™tes optimis√©es

```typescript
// Requ√™te avec jointure pour enrichissement
const { data } = await supabaseClient
  .from("turntagged")
  .select(
    `
    id,
    call_id,
    start_time,
    end_time,
    tag,
    next_turn_verbatim,
    lpltag!inner(color)
  `
  )
  .eq("call_id", callId);
```

## Gestion des erreurs

### Validation des donn√©es

```typescript
const fetchTaggingTranscription = useCallback(async (callId: string) => {
  try {
    // √âtape 1 : V√©rification existence transcript
    const { data: transcriptData, error: transcriptError } =
      await supabaseClient
        .from("transcript")
        .select("transcriptid")
        .eq("callid", callId)
        .single();

    if (transcriptError || !transcriptData?.transcriptid) {
      console.warn("‚ùå Transcript ID introuvable pour l'appel:", callId);
      setTaggingTranscription([]);
      return;
    }

    // √âtape 2 : R√©cup√©ration des mots avec validation
    const { data: wordsData, error: wordsError } = await supabaseClient
      .from("word")
      .select("*")
      .eq("transcriptid", transcriptData.transcriptid)
      .order("startTime", { ascending: true });

    if (wordsError) {
      console.error("‚ùå Erreur r√©cup√©ration des mots:", wordsError);
      setTaggingTranscription([]);
    } else {
      // Validation des donn√©es temps
      const validWords =
        wordsData?.filter(
          (word) => word.startTime >= 0 && word.endTime > word.startTime
        ) || [];

      setTaggingTranscription(validWords);
    }
  } catch (error) {
    console.error(
      "‚ùå Erreur inattendue lors du chargement transcription:",
      error
    );
    setTaggingTranscription([]);
  }
}, []);
```

### √âtats d'erreur

```typescript
// Extension possible avec √©tats d'erreur
const [error, setError] = useState<string | null>(null);
const [isLoading, setIsLoading] = useState(false);

const fetchTaggingCalls = useCallback(async () => {
  setIsLoading(true);
  setError(null);

  try {
    const { data, error } = await supabaseClient
      .from("call")
      .select("*")
      .eq("is_tagging_call", true)
      .eq("preparedfortranscript", true);

    if (error) throw error;

    setTaggingCalls(data ?? []);
  } catch (err) {
    setError(err instanceof Error ? err.message : "Erreur inconnue");
    console.error("‚ùå Erreur fetch appels tagging:", err);
  } finally {
    setIsLoading(false);
  }
}, []);
```

## Patterns d'architecture

### S√©paration des responsabilit√©s

```typescript
// TaggingDataContext : √âtat et logique m√©tier
// ‚Üí Composants UI : Pr√©sentation et interaction
// ‚Üí Hooks personnalis√©s : Logique r√©utilisable

// Exemple de hook personnalis√©
const useTaggingSelection = () => {
  const [selectionStart, setSelectionStart] = useState<number | null>(null);
  const [selectionEnd, setSelectionEnd] = useState<number | null>(null);

  const resetSelection = () => {
    setSelectionStart(null);
    setSelectionEnd(null);
  };

  const handleWordSelection = (index: number) => {
    if (!selectionStart) {
      setSelectionStart(index);
    } else if (!selectionEnd && index !== selectionStart) {
      setSelectionEnd(Math.max(selectionStart, index));
    } else {
      setSelectionStart(index);
      setSelectionEnd(null);
    }
  };

  return {
    selectionStart,
    selectionEnd,
    resetSelection,
    handleWordSelection,
    hasSelection: selectionStart !== null && selectionEnd !== null,
  };
};
```

### Int√©gration avec d'autres contextes

```typescript
// Utilisation combin√©e avec AudioContext pour lecteur avanc√©
function AdvancedTaggingPlayer() {
  const {
    audioSrc,
    playerRef,
    taggedTurns,
    playAudioAtTimestamp
  } = useTaggingData();

  const {
    executeWithLock,
    playSegment
  } = useAudio(); // R√©utilisation du contexte audio principal

  const playTaggedSegment = (tag: TaggedTurn) => {
    executeWithLock(async () => {
      playSegment(tag.start_time, tag.end_time);
    });
  };

  return (
    <div>
      {taggedTurns.map(tag => (
        <button
          key={tag.id}
          onClick={() => playTaggedSegment(tag)}
        >
          √âcouter "{tag.tag}"
        </button>
      ))}
    </div>
  );
}
```

## Extensions et √©volutions

### Nouveaux types de tags

```typescript
// Extension pour tags hi√©rarchiques
interface HierarchicalTag extends Tag {
  category: string; // Cat√©gorie du tag
  subcategory?: string; // Sous-cat√©gorie
  severity: "low" | "medium" | "high"; // Niveau de s√©v√©rit√©
  autoDetected: boolean; // Tag d√©tect√© automatiquement
}

// Extension pour m√©tadonn√©es enrichies
interface EnrichedTaggedTurn extends TaggedTurn {
  confidence?: number; // Confiance de l'annotation
  annotator?: string; // Qui a ajout√© le tag
  validated?: boolean; // Tag valid√© par un expert
  notes?: string; // Notes additionnelles
}
```

### Analytics et reporting

```typescript
// Hook pour analytics des tags
const useTaggingAnalytics = (callId?: string) => {
  const { taggedTurns, tags } = useTaggingData();

  const analytics = useMemo(() => {
    if (!taggedTurns.length) return null;

    const tagCounts = taggedTurns.reduce(
      (acc, turn) => {
        acc[turn.tag] = (acc[turn.tag] || 0) + 1;
        return acc;
      },
      {} as Record<string, number>
    );

    const totalDuration = taggedTurns.reduce(
      (acc, turn) => acc + (turn.end_time - turn.start_time),
      0
    );

    const averageTagDuration = totalDuration / taggedTurns.length;

    return {
      tagCounts,
      totalTaggedTime: totalDuration,
      averageTagDuration,
      uniqueTagsCount: Object.keys(tagCounts).length,
      mostUsedTag: Object.entries(tagCounts).sort((a, b) => b[1] - a[1])[0],
    };
  }, [taggedTurns]);

  return analytics;
};
```

### Export et import

```typescript
// Fonctions d'export des donn√©es de tagging
const exportTaggingData = (callId: string) => {
  const { taggedTurns, taggingTranscription } = useTaggingData();

  const exportData = {
    callId,
    exportDate: new Date().toISOString(),
    taggedTurns: taggedTurns.map((turn) => ({
      ...turn,
      verbatim: taggingTranscription
        .filter(
          (word) =>
            word.startTime >= turn.start_time && word.endTime <= turn.end_time
        )
        .map((word) => word.word)
        .join(" "),
    })),
    statistics: {
      totalTags: taggedTurns.length,
      totalTaggedTime: taggedTurns.reduce(
        (acc, turn) => acc + (turn.end_time - turn.start_time),
        0
      ),
    },
  };

  const blob = new Blob([JSON.stringify(exportData, null, 2)], {
    type: "application/json",
  });
  const url = URL.createObjectURL(blob);

  const a = document.createElement("a");
  a.href = url;
  a.download = `tagging-data-${callId}-${Date.now()}.json`;
  a.click();

  URL.revokeObjectURL(url);
};
```

## Bonnes pratiques

### ‚úÖ Do

- **Valider les donn√©es** avant stockage (temps, IDs, etc.)
- **Enrichir les tags** avec couleurs lors de l'affichage
- **G√©rer les erreurs** gracieusement avec fallbacks
- **Optimiser les requ√™tes** avec select sp√©cifiques
- **Nettoyer les √©tats** lors des changements d'appel

### ‚ùå Don't

- **Modifier directement** les arrays d'√©tat sans setState
- **Oublier la validation** des timestamps audio
- **Ignorer les cas** o√π audioSrc est null
- **Dupliquer la logique** de lecteur audio
- **Bloquer l'UI** pendant les chargements

### Performance tips

```typescript
// ‚úÖ M√©morisation des calculs co√ªteux
const enrichedTags = useMemo(() => {
  return taggedTurns.map((turn) => ({
    ...turn,
    duration: turn.end_time - turn.start_time,
    color: tags.find((t) => t.tag === turn.tag)?.color ?? "transparent",
  }));
}, [taggedTurns, tags]);

// ‚úÖ Debouncing des s√©lections rapides
const debouncedSelection = useCallback(
  debounce((wordIndex: number) => {
    handleWordSelection(wordIndex);
  }, 100),
  []
);
```

Le TaggingDataContext constitue un √©cosyst√®me complet et sp√©cialis√© pour l'annotation temporelle des appels, offrant une interface riche et performante pour l'analyse qualitative des conversations avec un syst√®me de tags flexible et extensible.

---

## R√©sum√© des 4 contextes

Voici un aper√ßu de l'architecture compl√®te des contextes :

- **AudioContext** : Gestion audio centrale avec protection concurrentielle et segments
- **AppContext** : √âtat global m√©tier (entreprises, domaines, nudges, UI)
- **CallDataContext** : Hub des donn√©es d'appels (transcriptions, post-its, coaching)
- **TaggingDataContext** : √âcosyst√®me sp√©cialis√© d'annotation temporelle

Cette architecture en couches garantit une s√©paration claire des responsabilit√©s tout en permettant une int√©gration fluide entre les diff√©rentes fonctionnalit√©s de la plateforme.
